{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Environment Setup: Installing Required Python Libraries\n",
        "\n",
        "This cell installs all external Python libraries required for the notebook to run successfully. It ensures that the computational environment has the necessary quantum computing, scientific computing, and data analysis dependencies.\n",
        "\n",
        "###Quantum computing Libraries\n",
        "* `qiskit`: IBM’s open-source framework for quantum computing, used to construct, simulate, and run quantum circuits.\n",
        "\n",
        "* `qiskit-aer`: Provides high-performance simulators for quantum circuits, enabling execution without access to real quantum hardware.\n",
        "\n",
        "* `qiskit-algorithms`: Contains high-level quantum algorithms (e.g., optimization, variational algorithms, and sampling routines) built on top of Qiskit primitives\n",
        "\n",
        "###Scientific computin and data handling libraries\n",
        "\n",
        "\n",
        "* `numpy`: Core numerical library for array-based computations and linear algebra.\n",
        "\n",
        "* `pandas`: Used for structured data manipulation, tabular datasets, and data analysis workflows.\n",
        "\n",
        "* `matplotlib`: Provides plotting and visualization utilities for results and diagnostics.\n",
        "\n",
        "* `scipy`: Supplies scientific routines such as optimization, statistics, and numerical solvers.\n",
        "\n",
        "* `openpyxl`: Enables reading from and writing to Excel (.xlsx) files, useful for exporting results."
      ],
      "metadata": {
        "id": "8wYLZ0gNrIl9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SnkQls8LjTpi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8341244e-d720-4570-c6dc-817489cbb957"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m327.8/327.8 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.4/54.4 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q qiskit qiskit-aer qiskit-algorithms\n",
        "!pip install -q numpy pandas matplotlib scipy openpyxl"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import qiskit\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(f\"Qiskit version:{qiskit.__version__}\")\n",
        "print(f\"NumPy version:{np.__version__}\")\n",
        "print(f\"Pandas version: {pd.__version__}\")"
      ],
      "metadata": {
        "id": "4X94c6xSjmjB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25f09c90-25c0-4866-e0b0-58fe6e10bfcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Qiskit version:2.2.3\n",
            "NumPy version:2.0.2\n",
            "Pandas version: 2.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Importing dependencies and configuring the environment\n",
        "\n",
        "**Core scientific and data libraries**: `numpy`, `pandas`\n",
        "\n",
        "**Type hinting and structured data utilities**:\n",
        "* `typing`: enables static type hints for improved code readability and maintainability. `Dict`, `List`, `Tuple`, `Optional` are used to clearly specify function inputs and outputs.\n",
        "\n",
        "* `dataclass`: facilitates the creation of lightweight classes for stroin structured data with minimal boilerplate code.\n",
        "\n",
        "**Quantum computing imports**\n",
        "* `QuantumCircuit`: Core object used to define quantum circuits.\n",
        "\n",
        "Optimizers:\n",
        "\n",
        "* `COBYLA`: Gradient-free classical optimizer suited for small-scale variational problems.\n",
        "\n",
        "* `SPSA`: Noise-robust optimizer commonly used in quantum settings.\n",
        "\n",
        "* `Sampler`: Executes quantum circuits and returns measurement samples.\n",
        "\n",
        "* `QuadraticProgram`: Represents optimization problems in a mathematical programming form.\n",
        "\n",
        "* `QuadraticProgramToQubo`: Converts constrained quadratic programs into QUBO (Quadratic Unconstrained Binary Optimization) form, which is required by QAOA.\n",
        "\n",
        "Availability Flag\n",
        "\n",
        "`QISKIT_AVAILABLE`:\n",
        "\n",
        "* Set to `True` if all Qiskit imports succeed.\n",
        "\n",
        "* Set to `False` if Qiskit is not installed or unavailable.\n",
        "\n",
        "* This flag allows the rest of the notebook to gracefully degrade to classical alternatives or skip quantum-specific sections when quantum libraries are missing."
      ],
      "metadata": {
        "id": "PgELlI6lsZ2P"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3IdGkQkrJqdw"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from typing import Dict, List, Tuple, Optional\n",
        "from dataclasses import dataclass\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "#Quantum imports\n",
        "try:\n",
        "  from qiskit import QuantumCircuit\n",
        "  from qiskit_algorithms import QAOA\n",
        "  from qiskit_algorithms.optimizers import COBYLA, SPSA\n",
        "  from qiskit.primitives import Sampler\n",
        "  from qiskit_optimization import QuadraticProgram\n",
        "  from qiskit_optimization.converters import QuadraticProgramToQubo\n",
        "  QISKIT_AVAILABLE=True\n",
        "except ImportError:\n",
        "  QISKIT_AVAILABLE=False"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Portfolio optimization configuration\n",
        "This cell defines a configuration container for the portfolio optimization problem using a Python `dataclass`. It centralizes all tunable parameters controlling risk, constraints, and quantum algorithm setting\n",
        "\n",
        "The configuration controls three main aspects of the system:\n",
        "\n",
        "1. **Portfolio structure and constraints**\n",
        "\n",
        "It specifies the size of the investment universe, limits how many positions can be changed during rebalancing, and enforces diversification through sector exposure caps. These parameters define the feasible solution space before any optimization is performed.\n",
        "\n",
        "2. **Risk and cost modeling**\n",
        "\n",
        "The configuration includes a risk aversion parameter that balances expected returns against portfolio risk, as well as a transaction cost multiplier that penalizes excessive trading. These values directly influence how the optimization objective is constructed, shaping the trade-off between performance and stability.\n",
        "\n",
        "3. **Quantum optimization behavior**\n",
        "\n",
        "The configuration determines whether quantum methods are enabled and, if so, how complex the quantum algorithm should be. The parameter controls the expressiveness of the quantum circuit, while a global quantum-enabled flag allows the system to seamlessly switch between quantum and classical solvers depending on availability or experimental needs.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1EKWweNkuVbO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class PortfolioConfig:\n",
        "  \"\"\"Configuration for portfolio optimization\"\"\"\n",
        "  portfolio_size: int=20\n",
        "  max_position_changes: int=10\n",
        "  risk_aversion: float=0.5\n",
        "  transaction_cost_mult : float=1.0\n",
        "  sector_limit: float=0.4\n",
        "  qaoa_depth: int=2\n",
        "  quantum_enabled: bool=True\n"
      ],
      "metadata": {
        "id": "0DfFwtHYLo3N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Portfolio data processing and preparation\n",
        "**Initialization and Data Preprocessing Flow**\n",
        "\n",
        "Upon initialization, the processor creates a defensive copy of the input dataset to avoid mutating the original data source. It then immediately triggers an internal preprocessing routine.\n",
        "\n",
        "This preprocessing step standardizes the dataset by:\n",
        "\n",
        "* Correcting inconsistent or malformed column names.\n",
        "\n",
        "* Ensuring that key financial fields are converted to numeric types, coercing invalid values to missing values.\n",
        "\n",
        "* Handling missing portfolio position data by assuming a neutral (zero) prior position where information is unavailable.\n",
        "\n",
        "By the end of this stage, the dataset is guaranteed to be clean, numerically consistent, and safe for quantitative analysis.\n",
        "\n",
        "**Covariance and risk structure modelling**\n",
        "\n",
        "Once the data is prepared, the processor can generate a realistic covariance matrix that captures asset-level risk and interdependence.\n",
        "\n",
        "Rather than relying on historical return time series, the covariance structure is synthesized using:\n",
        "\n",
        "* Market capitalization as a proxy for volatility, based on the empirical observation that smaller-cap assets tend to exhibit higher volatility.\n",
        "\n",
        "* Sector-based correlation assumptions, where assets within the same sector are modeled as more strongly correlated than assets across different sectors.\n",
        "\n",
        "The flow proceeds by:\n",
        "\n",
        "1. Estimating individual asset volatilities from market capitalization.\n",
        "\n",
        "2. Constructing a correlation matrix that reflects sector relationships.\n",
        "\n",
        "3. Enforcing symmetry and numerical stability.\n",
        "\n",
        "4. Converting the correlation structure into a covariance matrix using the estimated volatilities.\n",
        "\n",
        "This approach provides a plausible risk model even when historical data is sparse or unavailabl\n",
        "\n",
        "**Risk-adjusted performance estimation**\n",
        "\n",
        "Using the synthesized covariance structure, the processor computes risk-adjusted performance metrics for each asset.\n",
        "\n",
        "Specifically, it calculates Sharpe ratios by:\n",
        "\n",
        "* Extracting individual asset volatilities from the covariance matrix.\n",
        "\n",
        "* Adjusting expected returns by a configurable risk-free rate.\n",
        "\n",
        "* Normalizing returns by asset-level risk.\n",
        "\n",
        "The resulting Sharpe ratios provide a standardized measure of return per unit of risk and serve as a key ranking signal for asset selection\n",
        "\n",
        "**Intelligent asset universe reduction**\n",
        "\n",
        "To ensure computational tractability—especially for quantum optimization—the processor includes a smart asset screening mechanism.\n",
        "\n",
        "This screening stage reduces a potentially large asset universe to a manageable subset by:\n",
        "\n",
        "* Ranking assets based on their Sharpe ratios.\n",
        "\n",
        "* Enforcing minimum representation from each sector to preserve diversification.\n",
        "\n",
        "* Selecting top-performing assets within each sector in a first pass.\n",
        "\n",
        "* Filling any remaining slots with the highest-ranked assets overall, regardless of sector.\n",
        "\n",
        "The final output is a compact, diversified asset set that balances risk-adjusted performance with sector coverage, making it suitable for both classical and quantum portfolio optimization.\n"
      ],
      "metadata": {
        "id": "b2Q65vMXw_p-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PortfolioDataProcessor:\n",
        "  \"\"\"Processes and prepares portfolio data\"\"\"\n",
        "  def __init__(self, df: pd.DataFrame):\n",
        "    self.df=df.copy()\n",
        "    self._preprocess_data()\n",
        "\n",
        "  def _preprocess_data(self):\n",
        "    \"\"\"Clean and prepare the dataset\"\"\"\n",
        "    #Fix column name\n",
        "    if '0Market_Cap (billions)' in self.df.columns:\n",
        "      self.df.rename(columns={'0Market_Cap (billions)':'Market_Cap'}, inplace=True)\n",
        "\n",
        "    #Ensure numeric types\n",
        "    numeric_cols=['Expected_Return', 'Transaction_Cost','Market_Cap', 'Previous_Position']\n",
        "    for col in numeric_cols:\n",
        "      if col in self.df.columns:\n",
        "        self.df[col]=pd.to_numeric(self.df[col], errors='coerce')\n",
        "\n",
        "    #fill any mssing previous positions with 0\n",
        "    self.df['Previous_Position'].fillna(0, inplace=True)\n",
        "\n",
        "  def generate_sector_covariance(self)-> np.ndarray:\n",
        "    \"\"\"\n",
        "    Generate realistic covariance matrix based on sector relationships\n",
        "    and market cap (as proxy for volatility)\n",
        "    \"\"\"\n",
        "    n=len(self.df)\n",
        "\n",
        "    #Calculate volatility based on market cap (inverse relationships)\n",
        "    #Smaller components typically have higher\n",
        "    volatilities=0.15+0.35 /np.log(self.df['Market_Cap']+1)\n",
        "\n",
        "    #Create correlation matrix based on sectors\n",
        "    sectors=self.df['Sector'].values\n",
        "    correlation=np.zeros((n, n))\n",
        "\n",
        "    for i in range(n):\n",
        "      for j in range(n):\n",
        "        if i==j:\n",
        "          correlation[i, j]=1.0\n",
        "        elif sectors[i]==sectors[j]:\n",
        "          #Same sector: hih correlation(0.5-0.7)\n",
        "          correlation[i, j]=0.6+0.1*np.random.randn()*0.1\n",
        "        else:\n",
        "          #Different sector: low correlation (0.05-0.15)\n",
        "          correlation[i, j]=0.1+0.05*np.random.randn()*0.1\n",
        "\n",
        "    #Ensure correlation is symmetric and positive semi-definits\n",
        "    correlation=(correlation+correlation.T)/2\n",
        "\n",
        "    #Convert to covariance using volatilities\n",
        "    vol_matrix=np.outer(volatilities, volatilities)\n",
        "    covariance=correlation*vol_matrix\n",
        "\n",
        "    return covariance\n",
        "\n",
        "  def calculate_sharpe_ratios(self, risk_free_rate: float=0.02)-> pd.Series:\n",
        "    \"\"\"Calculate Sharpe ratio for each asset\"\"\"\n",
        "    volatilities=np.sqrt(np.diag(self.generate_sector_covariance()))\n",
        "    sharpe_ratios=(self.df['Expected_Return']-risk_free_rate)/volatilities\n",
        "    return pd.Series(sharpe_ratios, index=self.df.index)\n",
        "\n",
        "  def smart_asset_screening(self, target_size: int=20)-> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Intelligently reduce asset universe usng Sharpe ratio\n",
        "    while minimizn sector diversification\n",
        "    \"\"\"\n",
        "    #Calculate Sharpe rtios\n",
        "    sharpe_ratios=self.calculate_sharpe_ratios()\n",
        "    self.df['Sharpe_Ratio']=sharpe_ratios\n",
        "\n",
        "    #Get sector distribution\n",
        "    sectors=self.df['Sector'].unique()\n",
        "    min_per_sector=max(2, target_size//len(sectors))\n",
        "\n",
        "    selected_assets=[]\n",
        "\n",
        "    #first pass:Select top assests from each sector\n",
        "    for sector in sectors:\n",
        "      sector_assets=self.df[self.df['Sector']==sector].nlargest(\n",
        "      min_per_sector,'Sharpe_Ratio'\n",
        "      )\n",
        "      selected_assets.append(sector_assets)\n",
        "\n",
        "    selected_df=pd.concat(selected_assets)\n",
        "\n",
        "    #Second pass: Fill remaining slots with best overall Sharpe ratios\n",
        "    if len(selected_df)<target_size:\n",
        "      remaining=self.df[~self.df.index.isin(selected_df.index)]\n",
        "      additional=remaining.nlargest(\n",
        "          target_size-len(selected_df), 'Sharpe_Ratio'\n",
        "      )\n",
        "      selected_df=pd.concat([selected_df, additional])\n",
        "\n",
        "    return selected_df.head(target_size).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "k_OnbZj-xPX8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##QUBO formulator\n",
        "This component is responsible for translating the portfolio optimization problem into a mathematical form suitable for quantum optimization. It serves as the bridge between financial intuition (returns, risk, costs, constraints) and the formal representation required by the quantum algorithms.\n",
        "\n",
        "After portfolio data has been cleaned and a covariance matrix constructed, the QUBO formulator takes over, its task is to encode the entire optimization obejective into a single quadratic energy function over binary decision variables, where each variable represents whether an asset is included in the portfolio.\n",
        "\n",
        "The output of this module is a mathematical object that can be consumed by a quantum alorithm via an equivalent Ising Hamiltonian.\n",
        "\n",
        "##QUBO construction logic\n",
        "The optimization problem is constructed in two parts: linear terms and quadratic terms.\n",
        "\n",
        "**Linear Terms — Asset-Level Effects**\n",
        "\n",
        "The linear component captures effects that depend on individual asset selection:\n",
        "\n",
        "* Expected returns are encoded with a negative sign so that maximizing return becomes equivalent to minimizing energy.\n",
        "\n",
        "* Transaction costs penalize changes from previous portfolio positions, discouraging unnecessary turnover.\n",
        "\n",
        "* The formulation approximates position changes using asymmetric penalties for buying and selling, allowing prior portfolio state to influence the optimization outcome\n",
        "\n",
        "**Quadratic Terms — Risk and Interactions**\n",
        "\n",
        "The quadratic component captures interactions between assets:\n",
        "\n",
        "* Portfolio risk is modeled through the covariance matrix, scaled by a configurable risk-aversion parameter.\n",
        "\n",
        "* This term penalizes combinations of assets that jointly increase portfolio variance, encouraging diversification at the optimization level.\n",
        "\n",
        "**Portfolio Size Constraint via Penalty Method**\n",
        "\n",
        "Since QUBO problems are unconstrained by definition, the portfolio size constraint is enforced using a quadratic penalty formulation.\n",
        "\n",
        "The logic is as follows:\n",
        "\n",
        "* The desired number of selected assets is specified in the configuration.\n",
        "\n",
        "* A large penalty weight is computed dynamically to dominate the objective whenever the constraint is violated.\n",
        "\n",
        "* Both linear and quadratic coefficients are adjusted so that solutions selecting too many or too few assets incur a high energy cost.\n",
        "\n",
        "This converts a hard combinatorial constraint into a soft penalty embedded directly in the QUBO energy function.\n",
        "\n",
        "**QUBO Representation**\n",
        "\n",
        "The result of the formulation process is:\n",
        "\n",
        "* A quadratic coefficient matrix representing pairwise asset interactions.\n",
        "\n",
        "* A linear coefficient vector representing asset-level costs and benefits.\n",
        "\n",
        "Together, these fully define the QUBO objective function to be minimized.\n",
        "\n",
        "**Ising Hamiltonian conversion**\n",
        "\n",
        "To support quantum execution, the QUBO is further converted into an Ising Hamiltonian, the native representation used by quantum algorithms.\n",
        "\n",
        "This conversion:\n",
        "\n",
        "* Maps binary decision variables to spin variables.\n",
        "\n",
        "* Separates the problem into linear (`h`) and quadratic (`J`) spin coefficients.\n",
        "\n",
        "* Computes a constant energy offset that preserves equivalence between the QUBO and Ising formulations.\n",
        "\n",
        "The resulting Ising model can be directly passed to QAOA or other variational quantum algorithms."
      ],
      "metadata": {
        "id": "RsL5HSKOOxe0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class QUBOFormulator:\n",
        "  \"\"\"Formulates the QUBO problem for quantum optimization\"\"\"\n",
        "  def __init__(self, df: pd.DataFrame, covariance: np.ndarray, config: PortfolioConfig):\n",
        "    self.df=df\n",
        "    self.covariance=covariance\n",
        "    self.config=config\n",
        "    self.n_assets=len(df)\n",
        "\n",
        "  def build_qubo_matrix(self)-> Tuple[np.ndarray, np.ndarray]:\n",
        "    \"\"\"\n",
        "    Build QUBO matrix Q\n",
        "    Minimize\n",
        "    \"\"\"\n",
        "    n=self.n_assets\n",
        "\n",
        "    #Linear terms (c vector)\n",
        "    linear=np.zeros(n)\n",
        "\n",
        "    #Maximize returns(negative because we minimize)\n",
        "    linear-=self.df['Expected_Return'].values\n",
        "\n",
        "    #Transaction costs\n",
        "    prev_positions=self.df['Previous_Position'].values\n",
        "    transaction_penalties=self.df['Transaction_Cost'].values*self.config.transaction_cost_mult\n",
        "\n",
        "    #Penalty for changin positions: \\tau * |x-x_prev|\n",
        "    #this is approximated as: \\tau* (x-x_prev) for x_prev=0, and \\tau*(1-x) for x_prev=1\n",
        "    for i in range(n):\n",
        "      if prev_positions[i]==0:\n",
        "        linear[i]+=transaction_penalties[i] #Cost to buy\n",
        "      else:\n",
        "        linear[i]+=transaction_penalties[i] #Cost to not hold (sell)\n",
        "\n",
        "    #Quadratic terms (Q matrix)\n",
        "    quadratic=np.zeros((n, n))\n",
        "\n",
        "    #Risk Terms: \\lambda * \\sum\n",
        "    quadratic+=self.config.risk_aversion*self.covariance\n",
        "\n",
        "    #Portfolio size constraint (hard penalty)\n",
        "    # We wanr:\n",
        "    #Penalty:\n",
        "    target_size=self.config.portfolio_size\n",
        "    penalty_weight=max(np.abs(linear).max(), np.abs(quadratic).max())*10\n",
        "\n",
        "    #Expand\n",
        "    for i in range(n):\n",
        "      linear[i]-=2*penalty_weight*target_size\n",
        "      quadratic[i, 1]+=penalty_weight\n",
        "      for j in range(i+1, n):\n",
        "        quadratic[i, j]+=penalty_weight\n",
        "\n",
        "    return quadratic, linear\n",
        "\n",
        "  def build_ising_hamiltonian(self)-> Tuple[Dict, Dict, float]:\n",
        "    \"\"\"\n",
        "    Convert QUBO to Ising Hamiltonian\n",
        "    \"\"\"\n",
        "    Q, c=self.build_qubo_matrix()\n",
        "    n=self.n_assets\n",
        "\n",
        "    #Linear coefficients (h)\n",
        "    h={}\n",
        "    for i in range(n):\n",
        "      for j in range(n):\n",
        "        if i!=j:\n",
        "          h[i]+=Q[i, j]/2\n",
        "\n",
        "\n",
        "    #Quadratic coefficients (J)\n",
        "    J={}\n",
        "    for i in range(n):\n",
        "      for j in range(i+1, n):\n",
        "        J[(i, j)]=q[i, j]/4\n",
        "\n",
        "\n",
        "    #Offset\n",
        "    offset=sum(c)/2+sum(Q.flatten())/4\n",
        "\n",
        "    return h, J, offset\n",
        "\n"
      ],
      "metadata": {
        "id": "eV6qDcdyWc0c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Quantum optimizer- The execution layer\n",
        "This component implements the quantum optimization stage of the portfolio optimization pipeline. Its role is to take a problem already expressed as an Ising Hamiltonian and solve it using the Quantum Approximate Optimization Algorithm (QAOA).\n",
        "\n",
        "It represents the final execution layer where the abstract optimization problem is handed off to a quantum algorithm.\n",
        "\n",
        "**Conceptual Workflow**\n",
        "\n",
        "1.**Hamiltonian Assembly**\n",
        "\n",
        "The optimizer receives:\n",
        "\n",
        "* Linear spin coefficients (`h`), representing individual asset biases.\n",
        "\n",
        "* Pairwise interaction coefficients (`J`), representing asset-to-asset interactions.\n",
        "\n",
        "* A constant energy offset.\n",
        "\n",
        "These coefficients define the energy landscape that QAOA will attempt to minimize. The Hamiltonian is constructed using Pauli-Z operators, mapping each binary decision variable to a quantum spin.\n",
        "\n",
        "At this stage, the financial optimization problem exists entirely as a quantum mechanical object.\n",
        "\n",
        "2.**QAOA Configuration**\n",
        "\n",
        "The optimizer configures a QAOA instance with:\n",
        "\n",
        "* A sampler backend for executing quantum circuits.\n",
        "\n",
        "* A classical optimizer to tune variational parameters.\n",
        "\n",
        "* A configurable circuit depth (p), controlling the expressive power of the quantum ansatz.\n",
        "\n",
        "The depth parameter directly influences the trade-off between solution quality and computational cost\n",
        "\n",
        "3.**Hybrid Quantum–Classical Optimization Loop**\n",
        "\n",
        "QAOA operates as a hybrid algorithm:\n",
        "\n",
        "* The quantum circuit prepares parameterized quantum states.\n",
        "\n",
        "* Measurement results are sampled from the quantum system.\n",
        "\n",
        "* A classical optimizer updates circuit parameters to minimize the expected energy.\n",
        "\n",
        "This loop continues until convergence or until the optimization budget is exhausted.\n",
        "\n",
        "4.**Solution extraction**\n",
        "Once optimization completes:\n",
        "\n",
        "* The lowest-energy measured quantum state is identified.\n",
        "\n",
        "* The corresponding bitstring is extracted, representing the optimal selection of assets.\n",
        "\n",
        "* This bitstring is converted into a binary array, where each element indicates whether an asset is included in the portfolio.\n",
        "\n",
        "If a definitive measurement is unavailable, a conservative fallback solution is returned to ensure robustness."
      ],
      "metadata": {
        "id": "5Ainyt3kTOHo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class QuantumOptimizer:\n",
        "  \"\"\"Quantum optimization using QAOA\"\"\"\n",
        "  def __init__(self, config: PortfolioConfig):\n",
        "    self.config=config\n",
        "\n",
        "  def solve_qaoa(self, h: Dict, J: Dict, offset: float)-> np.ndarray:\n",
        "    \"\"\"\n",
        "    Solve using QAOA (Quantum Approximate Optimization Algorithm)\n",
        "    \"\"\"\n",
        "\n",
        "    n=len(h)\n",
        "\n",
        "    #Create Hamiltonian terms\n",
        "    from qiskit.quantum_info import SparsePauliOp\n",
        "\n",
        "    #Build Pauli operators\n",
        "    pauli_list=[]\n",
        "\n",
        "    #Linear terms (Z Operators)\n",
        "    for i, coeff in h.items():\n",
        "      pauli_str=['I']*n\n",
        "      pauli_str[i]='Z'\n",
        "      pauli_list.append((''.join(pauli_str), coeff))\n",
        "\n",
        "    #Create operator\n",
        "    hamiltonian=SparsePauliOp.from_list(pauli_list)\n",
        "\n",
        "    #Setup QAOA\n",
        "    optimizer=COBYLA(maxiter=1000)\n",
        "    qaoa=QAOA(\n",
        "        sampler=Sampler(),\n",
        "        optimizer=optimizer,\n",
        "        reps=self.config.qaoa_depth\n",
        "    )\n",
        "\n",
        "    #Run optimization\n",
        "    result=qaoa.compute_minimum_eigenvalue(hamiltonian)\n",
        "\n",
        "    #Extract best bitstring\n",
        "    if hasattr(result, 'best_measurement'):\n",
        "      bitstring=result.best_measurement['bitstring']\n",
        "    else:\n",
        "      #Fallback: Sample from state\n",
        "      bitstring='0'*n\n",
        "\n",
        "    #Convert to array\n",
        "    solution=np.array([int (b) for b in bitstring])\n",
        "\n",
        "    return solution"
      ],
      "metadata": {
        "id": "MxNRY7TnTTUb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Baseline and fallback\n",
        "This component implements classical optimization strategies for portfolio selection. It serves two critical roles in the system:\n",
        "\n",
        "1. A reliable fallback when quantum execution is unavailable or impractical.\n",
        "\n",
        "2. A baseline reference against which quantum optimization results can be compared.\n",
        "\n",
        "By providing classical heuristics and metaheuristics, this module ensures robustness, interpretability, and reproducibility of results.\n",
        "\n",
        "**Optimization Strategies Implemented**\n",
        "1.**Greedy Risk-Adjusted Selection**\n",
        "\n",
        "The greedy strategy provides a fast, deterministic approximation to the portfolio optimization problem.\n",
        "\n",
        "The logic proceeds as follows:\n",
        "\n",
        "* Each asset is scored using a risk-adjusted return metric, balancing expected return against volatility.\n",
        "\n",
        "* Transaction costs are incorporated as penalties, particularly discouraging changes from the existing portfolio.\n",
        "\n",
        "* Assets are ranked by their adjusted scores.\n",
        "\n",
        "* The top-ranked assets are selected until the target portfolio size is reached.\n",
        "\n",
        "2.**Simulated annealing for combinatorial optimization**\n",
        "\n",
        "To improve upon the greedy solution, the optimizer implements simulated annealing, a stochastic metaheuristic designed to escape local optima.\n",
        "\n",
        "The annealing process follows a physically inspired workflow:\n",
        "\n",
        "* Initialization begins from the greedy solution to ensure a strong starting point.\n",
        "\n",
        "* At each iteration, a neighboring portfolio is generated by swapping one included asset with one excluded asset, maintaining portfolio size.\n",
        "\n",
        "* The change in objective value (energy) determines whether the new solution is accepted:\n",
        "\n",
        "  * Improvements are always accepted.\n",
        "\n",
        "  * Worsening solutions may be accepted probabilistically, depending on temperature.\n",
        "\n",
        "* The temperature is gradually reduced according to a cooling schedule, shifting the search from exploration to exploitation.\n",
        "\n",
        "The best solution encountered during the process is retained and returned.\n",
        "\n",
        "**Objective function and enery interpretation**\n",
        "\n",
        "Both classical strategies rely on a shared objective function that mirrors the QUBO formulation:\n",
        "\n",
        "* Portfolio return contributes negatively to the energy, as higher returns are preferred.\n",
        "\n",
        "* Portfolio risk is penalized through a quadratic form involving the covariance matrix and a risk-aversion parameter.\n",
        "\n",
        "* Transaction costs penalize deviations from the previous portfolio state.\n",
        "\n",
        "The combined objective is minimized, ensuring consistency with both classical and quantum formulations."
      ],
      "metadata": {
        "id": "F_XYIX4gU3Zg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ClassicalOptimizer:\n",
        "  \"\"\"Classical optimization fallback and baseline\"\"\"\n",
        "  def __init__(self, config: PortfolioConfig):\n",
        "    self.config=config\n",
        "\n",
        "  def solve_greedy(self, df: pd.DataFrame, covariance: np.ndarray)-> np.ndarray:\n",
        "    \"\"\"\n",
        "    Greedy algorithm: Select assets with best risk-adjusted returns\n",
        "    \"\"\"\n",
        "    n=len(df)\n",
        "\n",
        "    #Calculate risk-adjusted scores\n",
        "    returns=df['Expected_Return'].values\n",
        "    volatilities=np.sqrt(np.diag(covariance))\n",
        "    transaction_costs=df['Transaction_Cost'].values\n",
        "    prev_positions=df['Previous_Position'].values\n",
        "\n",
        "    #Score=return / risk-transaction cost\n",
        "    scores=returns/(volatilities+1e-6)\n",
        "\n",
        "    #Penalize changes from previous positions\n",
        "    for i in range(n):\n",
        "      if prev_positions[i]==0:\n",
        "        scores[i]-=transaction_costs[i]*self.config.transaction_cost_mult\n",
        "\n",
        "    #Select top N assets\n",
        "    selected_indices=np.argsort(scores)[::-1][:self.config.portfolio_size]\n",
        "\n",
        "    solution=np.zeros(n, dtype=int)\n",
        "    solution[selected_indices]=1\n",
        "\n",
        "    return solution\n",
        "\n",
        "  def solve_simulated_annealing(self, df:pd.DataFrame, covariance: np.ndarray,\n",
        "                                iterations: int=10000)-> np.ndarray:\n",
        "      \"\"\"\n",
        "      Simulated annealing for QUBO\n",
        "      \"\"\"\n",
        "      n=len(df)\n",
        "\n",
        "      #Initialize with greedy solution\n",
        "      current_solution=self.solve_greedy(df, covariance)\n",
        "      current_energy=self._calculate_energy(current_solution, df, covariance)\n",
        "\n",
        "      best_solution=current_solution.copy()\n",
        "      best_energy=current_energy\n",
        "\n",
        "      #Annealing parameters\n",
        "      temp=1.0\n",
        "      temp_min=0.01\n",
        "      cooling_rate=0.9995\n",
        "\n",
        "      for iteration in range(iterations):\n",
        "        #Generate neighbour by flipping two bits (maintain portfolio size)\n",
        "        neighbor=current_solution.copy()\n",
        "\n",
        "        #Find one asset to remove an one to add\n",
        "        held_indices=np.where(current_solution==1)[0]\n",
        "        not_held_indices=np.where(current_solution==0)[0]\n",
        "\n",
        "        if len(held_indices)>0 and len(not_held_indices)>0:\n",
        "          remove_idx=np.random.choice(held_indices)\n",
        "          add_idx=np.random.choice(not_held_indices)\n",
        "\n",
        "          neighbor[remove_idx]=0\n",
        "          neighbor[add_idx]=1\n",
        "\n",
        "          #Calculate energy\n",
        "          neighbor_energy=self._calculate_energy(neighbor, df, covariance)\n",
        "\n",
        "          #Accept or reject\n",
        "          delta_e=neighbor_energy-current_energy\n",
        "          if delta_e<0 or np.random.random()<np.exp(-delta_e/ temp):\n",
        "            current_solution=neighbor\n",
        "            current_energy=neighbor_energy\n",
        "\n",
        "            if current_energy<best_energy:\n",
        "              best_solution=current_solution.copy()\n",
        "              best_energy=current_energy\n",
        "\n",
        "\n",
        "        #Cool down\n",
        "        temp=max(temp*cooling_rate, temp_min)\n",
        "\n",
        "      return best_solution\n",
        "\n",
        "  def _calculate_energy(self, solution: np.ndarray, df: pd.DataFrame,\n",
        "                        covariance: np.ndarray)-> float:\n",
        "\n",
        "      \"\"\"Calculate objective function value\"\"\"\n",
        "      returns=df['Expected_Return'].values\n",
        "      prev_positions=df['Previous_Position'].values\n",
        "      transaction_costs=df['Transaction_Cost'].values\n",
        "\n",
        "      #Portfolio return\n",
        "      portfolio_return=np.dot(returns, solution)\n",
        "\n",
        "      #Portfolio risk\n",
        "      portfolio_risk=np.dot(solution, np.dot(covariance, solution))\n",
        "\n",
        "      #Transaction costs\n",
        "      changes=np.abs(solution-prev_positions)\n",
        "      total_transaction_cost=np.dot(transaction_costs, changes)\n",
        "\n",
        "      #Objective (minimize)\n",
        "      energy=-portfolio_return+self.config.risk_aversion*portfolio_risk\\\n",
        "              +self.config.transaction_cost_mult*total_transaction_cost\n",
        "\n",
        "      return energy"
      ],
      "metadata": {
        "id": "MHnqeGoVXe4V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Constraint enforcer\n",
        "This component implements a deterministic post-processing stage that ensures all hard portfolio constraints are strictly satisfied. It is designed to operate after either quantum or classical optimization has produced a candidate solution.\n",
        "\n",
        "Because both QUBO-based quantum solvers and heuristic classical solvers may return solutions that slightly violate constraints, this module acts as a final corrective layer that guarantees feasibility.\n",
        "\n",
        "###Constraint enforcer flow\n",
        "1.**Maximum Position Changes (Turnover Constraint)**\n",
        "\n",
        "The first and most critical constraint enforced is the maximum number of allowed position changes relative to the previous portfolio.\n",
        "\n",
        "The logic is:\n",
        "\n",
        "* Count how many assets changed state (buy or sell).\n",
        "\n",
        "* If the number exceeds the allowed maximum:\n",
        "\n",
        "  * Rank changes by their impact on expected return.\n",
        "\n",
        "  * Retain only the most impactful changes.\n",
        "\n",
        "  * Revert lower-impact changes back to their previous positions.\n",
        "\n",
        "This ensures that turnover remains within operational limits while preserving the most economically meaningful adjustments.\n",
        "\n",
        "2.**Portfolio Size Constraint (Cardinality)**\n",
        "\n",
        "Once turnover is controlled, the solution is adjusted to ensure exactly the target number of assets is selected.\n",
        "\n",
        "This step:\n",
        "\n",
        "* Computes a risk-adjusted score for each asset.\n",
        "\n",
        "* Adds high-quality assets if the portfolio is too small.\n",
        "\n",
        "* Removes low-quality assets if the portfolio is too large.\n",
        "\n",
        "All adjustments are made while respecting the already-enforced turnover constraint.\n",
        "\n",
        "3.**Sector Diversification Constraints**\n",
        "\n",
        "Next, the enforcer ensures that no sector exceeds the maximum allowable allocation.\n",
        "\n",
        "For each sector:\n",
        "\n",
        "* If overrepresented, the weakest assets in that sector are removed.\n",
        "\n",
        "* Replacement assets are selected from other sectors based on risk-adjusted performance.\n",
        "\n",
        "This maintains diversification without significantly degrading portfolio quality.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Zw_bRnXcYnN4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ConstraintEnforcer:\n",
        "  \"\"\"Post-processing to enforce hard constraints\"\"\"\n",
        "  def __init__(self, config: PortfolioConfig):\n",
        "    self.config=config\n",
        "\n",
        "  def repair_solution(self, solution: np.ndarray, df: pd.DataFrame,\n",
        "                      covariance: np.ndarray)-> np.ndarray:\n",
        "\n",
        "      \"\"\"\n",
        "      Repair solution to satisfy all constraints\n",
        "      \"\"\"\n",
        "      solution=solution.copy()\n",
        "      prev_positions=df['Previous_Position'].values.astype(int)\n",
        "\n",
        "      #1. Fix max_chanes FIRST(hard constraint)\n",
        "      solution=self._fix_max_changes(solution, df, covariance)\n",
        "\n",
        "      #2. Fix size while respecting max_changes\n",
        "      solution=self._fix_portfolio_size_constrained(solution, df, covariance, prev_positions)\n",
        "\n",
        "      #3. Fix sectors while respecting max_changes\n",
        "      solution=self._fix_sector_limits_constrained(solution, df, covariance, prev_positions)\n",
        "\n",
        "      #4. Final check\n",
        "      solution=self._fix_portfolio_size_constrained(solution, df, covariance, prev_positions)\n",
        "\n",
        "      return solution\n",
        "\n",
        "  def _fix_portfolio_size_constrained(self, solution: np.ndarray, df: pd.DataFrame,\n",
        "                          covariance: np.ndarray, prev_positions: np.ndarray)-> np.ndarray:\n",
        "      \"\"\"Ensure exactly N assets are selected\"\"\"\n",
        "      current_size=solution.sum()\n",
        "      target_size=self.config.portfolio_size\n",
        "\n",
        "      if current_size==target_size:\n",
        "        return solution\n",
        "\n",
        "      #Calculate asset scores\n",
        "      returns=df['Expected_Return'].values\n",
        "      volatilities=np.sqrt(np.diag(covariance))\n",
        "      scores=returns / (volatilities+1e-6)\n",
        "\n",
        "      if current_size<target_size:\n",
        "        #Add best assets\n",
        "        available=np.where(solution==0)[0]\n",
        "        to_add=target_size-current_size\n",
        "        best_available=available[np.argsort(scores[available])[::-1][:to_add]]\n",
        "        solution[best_available]=1\n",
        "      else:\n",
        "        #Remove worst assets\n",
        "        held=np.where(solution==1)[0]\n",
        "        to_remove=current_size-target_size\n",
        "        worst_held=held[np.argsort(scores[held])[:to_remove]]\n",
        "        solution[worst_held]=0\n",
        "\n",
        "      return solution\n",
        "\n",
        "  def _fix_sector_limits_constrained(self, solution: np.ndarray, df: pd.DataFrame,\n",
        "                         covariance: np.ndarray, prev_positions: np.ndarray)->np.ndarray:\n",
        "      \"\"\"Ensure no sector exceeds maximum allocation\"\"\"\n",
        "      sectors=df['Sector'].values\n",
        "      unique_sectors=df['Sector'].unique()\n",
        "      max_per_sector=int(self.config.sector_limit*self.config.portfolio_size)\n",
        "\n",
        "      returns=df['Expected_Return'].values\n",
        "      volatilities=np.sqrt(np.diag(covariance))\n",
        "      scores=returns /(volatilities+1e-6)\n",
        "\n",
        "      for sector in unique_sectors:\n",
        "        sector_mask=sectors==sector\n",
        "        sector_count=(solution&sector_mask).sum()\n",
        "\n",
        "        if sector_count>max_per_sector:\n",
        "          #Remove worst assets from this sector\n",
        "          sector_indices=np.where(solution & sector_mask)[0]\n",
        "          to_remove=sector_count-max_per_sector\n",
        "          worst_in_sector=sector_indices[np.argsort(scores[sector_indices])[:to_remove]]\n",
        "          solution[worst_in_sector]=0\n",
        "\n",
        "          #Add best assets from other sectors\n",
        "          other_sectors_mask=~sector_mask& (solution==0)\n",
        "          available=np.where(other_sectors_mask)[0]\n",
        "          if len(available)>=to_remove:\n",
        "            best_others=available[np.argsort(scores[available])[::-1][:to_remove]]\n",
        "            solution[best_others]=1\n",
        "\n",
        "      return solution\n",
        "\n",
        "\n",
        "  def _fix_max_changes(self, solution: np.ndarray, df: pd.DataFrame,\n",
        "                       covariance: np.ndarray)-> np.ndarray:\n",
        "      \"\"\"Ensure position changes don't exceed K\"\"\"\n",
        "      prev_positions=df['Previous_Position'].values\n",
        "      changes=np.abs(solution-prev_positions)\n",
        "      num_changes=changes.sum()\n",
        "\n",
        "      if num_changes<=self.config.max_position_changes:\n",
        "        return solution\n",
        "\n",
        "      #Revert minimal-impact changes\n",
        "      changed_indices=np.where(changes==1)[0]\n",
        "\n",
        "      #Score changes by impact\n",
        "      returns=df['Expected_Return'].values\n",
        "      change_impacts=np.abs(returns[changed_indices])\n",
        "\n",
        "      #Keep most impactful changes\n",
        "      to_keep=self.config.max_position_changes\n",
        "      keep_indices=changed_indices[np.argsort(change_impacts)[::-1][:to_keep]]\n",
        "\n",
        "      #Revert others\n",
        "      revert_indices=changed_indices[~np.isin(changed_indices, keep_indices)]\n",
        "      solution[revert_indices]=prev_positions[revert_indices]\n",
        "\n",
        "      return solution"
      ],
      "metadata": {
        "id": "c7NcpUm1UK4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Portfolio Analyzer\n",
        "The PortfolioAnalyzer component is responsible for evaluating a finalized portfolio solution and translating it into financial, risk, and operational metrics that are easy to interpret.\n",
        "\n",
        "It produces a complete analytical summary suitable for:\n",
        "\n",
        "* Model evaluation\n",
        "\n",
        "* Strategy comparison\n",
        "\n",
        "* Reporting to decision-makers\n",
        "\n",
        "* Exporting results (e.g., Excel, dashboards\n",
        "\n",
        "**Output Summary**\n",
        "\n",
        "The analyzer returns a structured report containing:\n",
        "\n",
        "* Selected assets\n",
        "\n",
        "* Number of holdings\n",
        "\n",
        "* Expected return\n",
        "\n",
        "* Risk (volatility)\n",
        "\n",
        "* Sharpe ratio\n",
        "\n",
        "* Transaction costs\n",
        "\n",
        "* Number of position changes\n",
        "\n",
        "* Sector allocation percentages\n",
        "\n",
        "* Buy / Sell / Hold action lists\n",
        "\n",
        "This output is designed to be:\n",
        "\n",
        "* Machine-readable\n",
        "\n",
        "* Human-interpretable\n",
        "\n",
        "* Ready for visualization or export\n"
      ],
      "metadata": {
        "id": "bJCKbCO2aOeQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PortfolioAnalyzer:\n",
        "  \"\"\"Analyzes and reports portfolio metrics\"\"\"\n",
        "  @staticmethod\n",
        "  def calculate_metrics(solution: np.ndarray, df:pd.DataFrame,\n",
        "                        covariance: np.ndarray)-> Dict:\n",
        "\n",
        "      \"\"\"Calculate comprehensive portfolio metrics\"\"\"\n",
        "      selected_assets=df[solution==1].copy()\n",
        "\n",
        "      #Portfolio return\n",
        "      portfolio_return=selected_assets['Expected_Return'].sum()\n",
        "\n",
        "      #Portfolio risk (standard deviation)\n",
        "      selected_covariance=covariance[solution==1][:, solution==1]\n",
        "      portfolio_variance=np.sum(selected_covariance)\n",
        "      portfolio_risk=np.sqrt(portfolio_variance)\n",
        "\n",
        "      #Transaction costs\n",
        "      prev_positions=df['Previous_Position'].values\n",
        "      changes=np.abs(solution-prev_positions)\n",
        "      transaction_costs=(df['Transaction_Cost']*changes).sum()\n",
        "\n",
        "      #Sector allocation\n",
        "      sector_allocation=selected_assets.groupby('Sector').size().to_dict()\n",
        "      sector_percentages={k: v/len(selected_assets)*100 for k, v in sector_allocation.items()}\n",
        "\n",
        "      #Sharpe ratio (assuming risk-free rate=2%)\n",
        "      sharpe_ratio=(portfolio_return-0.02)/ (portfolio_risk+1e-6)\n",
        "\n",
        "      #Position changes\n",
        "      num_changes=changes.sum()\n",
        "\n",
        "      #Transaction list\n",
        "      buy_assets=df[((solution==1)& (prev_positions==0))]['Asset'].tolist()\n",
        "      sell_assets=df[((solution==0)& (prev_positions==1))]['Asset'].tolist()\n",
        "      hold_assets=df[((solution==1)& (prev_positions==1))]['Asset'].tolist()\n",
        "\n",
        "\n",
        "      return{\n",
        "          'selected_assets':selected_assets['Asset'].tolist(),\n",
        "          'num_assets':len(selected_assets),\n",
        "          'portfolio_return':portfolio_return,\n",
        "          'portfolio_risk':portfolio_risk,\n",
        "          'sharpe_ratio':sharpe_ratio,\n",
        "          'transaction_costs':transaction_costs,\n",
        "          'num_changes':int(num_changes),\n",
        "          'sector_allocation':sector_percentages,\n",
        "          'buy_list':buy_assets,\n",
        "          'sell_list':sell_assets,\n",
        "          'hold_list':hold_assets\n",
        "      }"
      ],
      "metadata": {
        "id": "GYgyXY0dTlms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Quantum Portfolio optimization\n",
        "The QuantumPortfolioOptimizer is the main orchestration layer of the portfolio optimization system.\n",
        "It coordinates data preparation, optimization strategy selection, constraint enforcement, and performance analysis into a single, reproducible workflow.\n",
        "\n",
        "Rather than focusing on a single solver, it is designed to flexibly support quantum, classical, and hybrid approaches, making it robust to both hardware availability and problem scale.\n",
        "\n",
        "The optimizer follows a six-stage pipeline, each stage building on the previous one:\n",
        "\n",
        "1. Data processing\n",
        "\n",
        "2. Asset screening\n",
        "\n",
        "3. QUBO / Ising problem formulation\n",
        "\n",
        "4. Optimization (quantum, classical, or hybrid)\n",
        "\n",
        "5. Constraint enforcement\n",
        "\n",
        "6. Portfolio analysis and reporting\n",
        "\n",
        "Each stage is deliberately modular, allowing different methods to be swapped without breaking the pipeline.\n",
        "\n"
      ],
      "metadata": {
        "id": "f3dnVcracJzs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class QuantumPortfolioOptimizer:\n",
        "  \"\"\"Main operator for quantum portfolio optimization\"\"\"\n",
        "  def __init__(self, config: PortfolioConfig):\n",
        "    self.config=config\n",
        "\n",
        "  def optimize(self, df: pd.DataFrame, method:str='hybrid')-> Tuple[np.ndarray, Dict]:\n",
        "    \"\"\"\n",
        "    Main optimization method\n",
        "\n",
        "    Args:\n",
        "      df:Portfolio data\n",
        "      method: 'quantum', 'classical', or 'hybrid'\n",
        "\n",
        "    Returns:\n",
        "      solution: Binary array including asset selection\n",
        "      metrics: Portfolio performance metrics\n",
        "    \"\"\"\n",
        "    #Step 1: Data processing\n",
        "    print(\"\\n[1/6] Processing data...\")\n",
        "    processor=PortfolioDataProcessor(df)\n",
        "\n",
        "    #Step 2: Smart screening (for quantum: use 2x, for classical: use 1.5x)\n",
        "    screening_size=min(30, self.config.portfolio_size*2) if method=='quantum' else self.config.portfolio_size+10\n",
        "    print(f\"[2/6] Screening assets (50 -> {screening_size})...\")\n",
        "    screened_df=processor.smart_asset_screening(target_size=screening_size)\n",
        "\n",
        "    #Generate covariance for second pairs\n",
        "    temp_processor=PortfolioDataProcessor(screened_df)\n",
        "    covariance=temp_processor.generate_sector_covariance()\n",
        "\n",
        "    print(f\" Reduced to {len(screened_df)} assets\")\n",
        "    print(f\" Sectors: {screened_df['Sector'].unique().tolist()}\")\n",
        "\n",
        "    #Step 3: QUBO formulation\n",
        "    print(\"\\n[3/6] Formulatin QUBO problem...\")\n",
        "    formulator=QUBOFormulator(screened_df, covariance, self.config)\n",
        "\n",
        "    #Step 4: Optimization\n",
        "    print(f\"\\n[4/6] Running {method} optimization...\")\n",
        "\n",
        "    if method=='quantum' and self.config.quantum_enabled and QISKIT_AVAILABLE:\n",
        "      h, J, offset=formulator.build_ising_hamiltonian()\n",
        "      quantum_opt=QuantumOptimizer(self.config)\n",
        "      try:\n",
        "        solution=quantum_opt.solve_qaoa(h, J, offset)\n",
        "        print(\" QAOA optimization complete\")\n",
        "      except Exception as e:\n",
        "        print(f\" Quantum optimization failed: {e}. Falling back to classical.\")\n",
        "        classical_opt=ClassicalOptimizer(self.config)\n",
        "        solution=classical_opt.solve_simulated_annealing(screened_df, covariance)\n",
        "\n",
        "    elif method=='hybrid':\n",
        "      #Use simulated annealing(quantum-inspired)\n",
        "      classical_opt=ClassicalOptimizer(self.config)\n",
        "      solution=classical_opt.solve_simulated_annealing(screened_df, covariance, iterations=5000)\n",
        "      print(\" Simulated annealing complete\")\n",
        "\n",
        "    else:\n",
        "      #Classical greedy\n",
        "      classical_opt=ClassicalOptimizer(self.config)\n",
        "      solution=classical_opt.solve_greedy(screened_df, covariance)\n",
        "      print(\" Greedy optimization complete\")\n",
        "\n",
        "\n",
        "    #Step 5: Constraint enforcement...\n",
        "    print(\"\\n[5/6] Enforcing constraints...\")\n",
        "    enforcer=ConstraintEnforcer(self.config)\n",
        "    solution=enforcer.repair_solution(solution, screened_df, covariance)\n",
        "    print(\"All constraints satisfied\")\n",
        "\n",
        "    #Step 6: Analysis\n",
        "    print(\"\\n[6/6] Analyzing results...\")\n",
        "    metrics=PortfolioAnalyzer.calculate_metrics(solution, screened_df, covariance)\n",
        "\n",
        "    return solution, metrics, screened_df"
      ],
      "metadata": {
        "id": "hjZR2GbPc-tQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_results(metrics: Dict):\n",
        "  print(f\"\\nPORTFOLIO SUMMARY\")\n",
        "  print(f\"Assets Selected: {metrics['num_assets']}\")\n",
        "  print(f\"Expected Return: {metrics['portfolio_return']*100:.2f}%\")\n",
        "  print(f\"Portfolio Risk:{metrics['portfolio_risk']*100:.2f}%\")\n",
        "  print(f\"Sharpe ratio:{metrics['sharpe_ratio']:.3f}\")\n",
        "  print(f\"Transaction Cost: ${metrics['transaction_costs']:.4f}\")\n",
        "\n",
        "\n",
        "  print(f\"\\nTRANSACTIONS ({metrics['num_changes']} changes)\")\n",
        "  print(f\"Buy: {len(metrics['buy_list'][:5])}\" +\n",
        "        (f\"... (+{len(metrics['buy_list'])-5} more)\" if len(metrics['buy_list'])>5 else \"\"))\n",
        "\n",
        "  print(f\" Sell: {len(metrics['sell_list'])} assets\")\n",
        "  if metrics['sell_list']:\n",
        "    print(f\"    {', '.join(metrics['sell_list'][:5])}\"+\n",
        "          (f\"... (+{len(metrics['sell_list'])-5} more)\" if len(metrics['sell_list'])>5 else \"\"))\n",
        "\n",
        "  print(f\"  Hold: {len(metrics['hold_list'])} assets\")\n",
        "\n",
        "  print(f\"\\nSECTOR ALLOCATION\")\n",
        "  for sector, pct in sorted(metrics['sector_allocation'].items(), key=lambda x: -x[1]):\n",
        "    bar='|'*int(pct/5)\n",
        "    print(f\"  {sector:8s} |{bar:<20s}{pct:5.1f}%\")"
      ],
      "metadata": {
        "id": "IanV6A8mLWYC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48gRXLaXt889",
        "outputId": "4525296d-b80f-4935-b882-615160f2a8d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__==\"__main__\":\n",
        "  df=pd.read_excel('/content/drive/MyDrive/AQC-PAQC-FinanceTrack-Dataset.xlsx')\n",
        "\n",
        "  config=PortfolioConfig(\n",
        "      portfolio_size=20,\n",
        "      max_position_changes=10,\n",
        "      risk_aversion=0.5,\n",
        "      transaction_cost_mult=1.0,\n",
        "      sector_limit=0.4,\n",
        "      qaoa_depth=2,\n",
        "      quantum_enabled=True\n",
        "  )\n",
        "\n",
        "  optimizer=QuantumPortfolioOptimizer(config)\n",
        "  solution, metrics, screened_df=optimizer.optimize(df, method='hybrid')\n",
        "\n",
        "  print_results(metrics)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xqb7Q3rLPe2t",
        "outputId": "9bc5a5a1-a8d3-42f2-df8b-16f8808c966a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[1/6] Processing data...\n",
            "[2/6] Screening assets (50 -> 30)...\n",
            " Reduced to 30 assets\n",
            " Sectors: ['ENERGY', 'CONS', 'HEALTH', 'FIN', 'TECH']\n",
            "\n",
            "[3/6] Formulatin QUBO problem...\n",
            "\n",
            "[4/6] Running hybrid optimization...\n",
            " Simulated annealing complete\n",
            "\n",
            "[5/6] Enforcing constraints...\n",
            "All constraints satisfied\n",
            "\n",
            "[6/6] Analyzing results...\n",
            "\n",
            "PORTFOLIO SUMMARY\n",
            "Assets Selected: 20\n",
            "Expected Return: 1400.44%\n",
            "Portfolio Risk:288.03%\n",
            "Sharpe ratio:4.855\n",
            "Transaction Cost: $0.5626\n",
            "\n",
            "TRANSACTIONS (16 changes)\n",
            "Buy: 5... (+3 more)\n",
            " Sell: 8 assets\n",
            "    ASSET_035, ASSET_037, ASSET_006, ASSET_011, ASSET_020... (+3 more)\n",
            "  Hold: 12 assets\n",
            "\n",
            "SECTOR ALLOCATION\n",
            "  ENERGY   |||||||               30.0%\n",
            "  CONS     |||||                 20.0%\n",
            "  HEALTH   |||||                 20.0%\n",
            "  FIN      ||||                  15.0%\n",
            "  TECH     ||||                  15.0%\n"
          ]
        }
      ]
    }
  ]
}